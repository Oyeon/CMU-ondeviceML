{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c499e7-fb3d-418d-a63c-f65fddfff6cc",
   "metadata": {},
   "source": [
    "## HardWard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2eb072-f5d6-42e0-bfc6-f7750e92fed9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "import torch\n",
    "import psutil\n",
    "\n",
    "# Python version\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print('----')\n",
    "print('----')\n",
    "\n",
    "# PyTorch version and CUDA availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print('----')\n",
    "print('----')\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print('----')\n",
    "print('----')\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print('----')\n",
    "print('----')\n",
    "\n",
    "\n",
    "# Operating System\n",
    "print(f\"Operating System: {platform.system()} {platform.release()} {platform.version()}\")\n",
    "print('----')\n",
    "print('----')\n",
    "\n",
    "\n",
    "# CPU Information\n",
    "cpu_info = psutil.cpu_times()\n",
    "print(f\"CPU Information: {cpu_info}\")\n",
    "print('----')\n",
    "print('----')\n",
    "\n",
    "\n",
    "# RAM Information\n",
    "ram_info = psutil.virtual_memory()\n",
    "print(f\"Total RAM: {ram_info.total / (1024 ** 3):.2f} GB\")\n",
    "print('----')\n",
    "print('----')\n",
    "print(f\"Available RAM: {ram_info.available / (1024 ** 3):.2f} GB\")\n",
    "print('----')\n",
    "print('----')\n",
    "\n",
    "\n",
    "# PyTorch configuration\n",
    "print(torch.__config__.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2843e69-5ec7-4fe7-91a4-6eacbcbb1842",
   "metadata": {},
   "source": [
    "## # of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfce5f-a882-4eb0-adaa-e883f232c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to count trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Example usage for GarmentClassifier model\n",
    "model = GarmentClassifier()\n",
    "total_params = count_parameters(model)\n",
    "print(f'Total trainable parameters: {total_params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed12d2-7b31-46f8-b98e-f7c77062c744",
   "metadata": {},
   "source": [
    "## FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350d511-9bfd-4c29-8812-87dbd66bafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute FLOPs for GarmentClassifier\n",
    "def compute_flops(model, input_size=(1, 28*28)):\n",
    "    flops = 0\n",
    "    \n",
    "    # fc1 FLOPs: (input_size * hidden_size) + hidden_size\n",
    "    flops += (input_size[1] * model.fc1.out_features) + model.fc1.out_features\n",
    "    \n",
    "    # fc2 FLOPs: (hidden_size * hidden_size) + hidden_size\n",
    "    flops += (model.fc1.out_features * model.fc2.out_features) + model.fc2.out_features\n",
    "    \n",
    "    # fc3 FLOPs: (hidden_size * output_size) + output_size\n",
    "    flops += (model.fc2.out_features * model.fc3.out_features) + model.fc3.out_features\n",
    "    \n",
    "    return flops\n",
    "\n",
    "# Example usage for GarmentClassifier model\n",
    "flops = compute_flops(model)\n",
    "print(f'Total FLOPs for one forward pass: {flops}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01aa550-89f1-4452-b7b3-7059c3391e6c",
   "metadata": {},
   "source": [
    "## Question 1 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d024a0-c5a4-4a17-9078-b21ac5a7832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('check/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c8d46-1557-43e9-9ec3-35aca1166bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for transform_type, depth, and width\n",
    "\n",
    "\n",
    "# Sample dataset row with config_name\n",
    "config_name_data = list(df['config_name'])\n",
    "\n",
    "# Function to split config_name into transform_type, depth, and width\n",
    "def parse_config_name(config_name):\n",
    "    parts = config_name.split('_')\n",
    "    transform_type = '_'.join(parts[:-2])  # Extract the transform type\n",
    "    depth = parts[-2]  # Extract the depth\n",
    "    width = parts[-1]  # Extract the width\n",
    "    return transform_type, depth, width\n",
    "\n",
    "# # Apply the function to config_name_data\n",
    "# for config_name in config_name_data:\n",
    "#     transform_type, depth, width = parse_config_name(config_name)\n",
    "#     print(f\"Config: {config_name} -> Transform Type: {transform_type}, Depth: {depth}, Width: {width}\")\n",
    "df[['transform', 'depth', 'width']] = df['config_name'].apply(lambda x: pd.Series(parse_config_name(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c639a-25c2-49d1-a16c-a6025d739b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터\n",
    "epochs = [1, 2]\n",
    "training_loss = [0.262538, 0.131841]\n",
    "validation_loss = [0.167623, 0.104640]\n",
    "test_loss = [0.148532, 0.100935]\n",
    "training_accuracy = [0.920561, 0.961895]\n",
    "validation_accuracy = [0.948833, 0.970250]\n",
    "test_accuracy = [0.955596, 0.970297]\n",
    "\n",
    "# Subplot 설정: 1x2 형식으로 Loss와 Accuracy 그래프를 나란히 배치\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Loss 그래프 (왼쪽 subplot)\n",
    "axes[0].plot(epochs, training_loss, marker='o', label='Training Loss', color='blue')\n",
    "axes[0].plot(epochs, validation_loss, marker='o', label='Validation Loss', color='orange', linestyle='--')\n",
    "axes[0].plot(epochs, test_loss, marker='o', label='Test Loss', color='green', linestyle=':')\n",
    "\n",
    "# Loss 포인트에 숫자 표시\n",
    "for i, txt in enumerate(training_loss):\n",
    "    axes[0].annotate(f'{txt:.4f}', (epochs[i], training_loss[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='blue')\n",
    "for i, txt in enumerate(validation_loss):\n",
    "    axes[0].annotate(f'{txt:.4f}', (epochs[i], validation_loss[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='orange')\n",
    "for i, txt in enumerate(test_loss):\n",
    "    axes[0].annotate(f'{txt:.4f}', (epochs[i], test_loss[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='green')\n",
    "\n",
    "# Loss 그래프 세부 설정\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_ylim(0, 0.3)  # Y축 범위를 정교하게 조정\n",
    "axes[0].set_title('Training, Validation, and Test Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 2. Accuracy 그래프 (오른쪽 subplot)\n",
    "axes[1].plot(epochs, training_accuracy, marker='x', label='Training Accuracy', color='blue')\n",
    "axes[1].plot(epochs, validation_accuracy, marker='x', label='Validation Accuracy', color='orange', linestyle='--')\n",
    "axes[1].plot(epochs, test_accuracy, marker='x', label='Test Accuracy', color='green', linestyle=':')\n",
    "\n",
    "# Accuracy 포인트에 숫자 표시\n",
    "for i, txt in enumerate(training_accuracy):\n",
    "    axes[1].annotate(f'{txt:.4f}', (epochs[i], training_accuracy[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='blue')\n",
    "for i, txt in enumerate(validation_accuracy):\n",
    "    axes[1].annotate(f'{txt:.4f}', (epochs[i], validation_accuracy[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='orange')\n",
    "for i, txt in enumerate(test_accuracy):\n",
    "    axes[1].annotate(f'{txt:.4f}', (epochs[i], test_accuracy[i]), textcoords=\"offset points\", xytext=(0,10), ha='center', color='green')\n",
    "\n",
    "# Accuracy 그래프 세부 설정\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_ylim(0.9, 1.0)  # Y축 범위를 정교하게 조정\n",
    "axes[1].set_title('Training, Validation, and Test Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# 레이아웃 조정 및 그래프 표시\n",
    "plt.tight_layout()\n",
    "plt.savefig('1_sub_plot.jpg')  # Loss 그래프를 JPG로 저장\n",
    "plt.close()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96392f-2555-4bbe-86fb-bbe0185c8670",
   "metadata": {},
   "source": [
    "## Question 3 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832363f-fa5e-411b-b7b8-c3ea82542be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv('check/cpu_results.csv')\n",
    "\n",
    "import ast\n",
    "\n",
    "# 문자열을 리스트로 변환\n",
    "epoch1_data = df.iloc[0]['inference_time']\n",
    "epcoh1_list = ast.literal_eval(epoch1_data)\n",
    "\n",
    "epoch2_data = df.iloc[1]['inference_time']\n",
    "epcoh2_list = ast.literal_eval(epoch2_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bc32a-29c5-477e-8789-bd344b3a0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 예시 데이터: 실제로는 길이가 20000인 리스트로 대체\n",
    "epoch1_list = epcoh1_list[0]\n",
    "epoch2_list = epcoh2_list[1]\n",
    "\n",
    "# Subplot을 사용하여 두 그래프를 하나의 그림에 포함 (1x2)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. epoch1 데이터\n",
    "data = epoch1_list\n",
    "\n",
    "# 이동 평균과 표준 편차 계산\n",
    "window_size = 100  # 이동 평균을 계산할 윈도우 크기\n",
    "rolling_mean = np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n",
    "rolling_std = [np.std(data[i:i+window_size]) for i in range(len(data) - window_size + 1)]\n",
    "\n",
    "# 첫 번째 subplot에 그리기 (좌측)\n",
    "axes[0].plot(rolling_mean, label='Moving Average', color='blue')\n",
    "axes[0].fill_between(range(len(rolling_mean)), \n",
    "                     rolling_mean - rolling_std, \n",
    "                     rolling_mean + rolling_std, \n",
    "                     color='lightblue', alpha=0.5, label='Standard Deviation')\n",
    "\n",
    "# 그래프 설정 및 epoch1 average time 추가\n",
    "axes[0].set_title('Epoch 1 - Moving Average and Standard Deviation')\n",
    "axes[0].set_xlabel('Index')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "axes[0].text(0.05, 0.95, 'Epoch 1 Average Time: 0.000401', transform=axes[0].transAxes, fontsize=12, \n",
    "             verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# 2. epoch2 데이터\n",
    "data = epoch2_list\n",
    "\n",
    "# 이동 평균과 표준 편차 계산\n",
    "window_size = 100  # 이동 평균을 계산할 윈도우 크기\n",
    "rolling_mean = np.convolve(data, np.ones(window_size) / window_size, mode='valid')\n",
    "rolling_std = [np.std(data[i:i+window_size]) for i in range(len(data) - window_size + 1)]\n",
    "\n",
    "# 두 번째 subplot에 그리기 (우측)\n",
    "axes[1].plot(rolling_mean, label='Moving Average', color='blue')\n",
    "axes[1].fill_between(range(len(rolling_mean)), \n",
    "                     rolling_mean - rolling_std, \n",
    "                     rolling_mean + rolling_std, \n",
    "                     color='lightblue', alpha=0.5, label='Standard Deviation')\n",
    "\n",
    "# 그래프 설정 및 epoch2 average time 추가\n",
    "axes[1].set_title('Epoch 2 - Moving Average and Standard Deviation')\n",
    "axes[1].set_xlabel('Index')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "axes[1].text(0.05, 0.95, 'Epoch 2 Average Time: 0.000435', transform=axes[1].transAxes, fontsize=12, \n",
    "             verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# 레이아웃 최적화\n",
    "plt.tight_layout()\n",
    "plt.savefig('3_sub_plot.jpg')  # Loss 그래프를 JPG로 저장\n",
    "plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b16448-507a-4261-b12b-9b3af1babf4c",
   "metadata": {},
   "source": [
    "## Question 6 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ca4fb-17b1-407d-a06a-4f14921a5eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('check/depth_results.csv')\n",
    "\n",
    "# Sample dataset row with config_name\n",
    "config_name_data = list(df['config_name'])\n",
    "\n",
    "# Function to split config_name into transform_type, depth, and width\n",
    "def parse_config_name(cofig_name):\n",
    "    parts = config_name.split('_')\n",
    "    transform_type = '_'.join(parts[:-2])  # Extract the transform type\n",
    "    depth = parts[-2]  # Extract the depth\n",
    "    width = parts[-1]  # Extract the width\n",
    "    return transform_type, depth, width\n",
    "\n",
    "# # Apply the function to config_name_data\n",
    "# for config_name in config_name_data:\n",
    "#     transform_type, depth, width = parse_config_name(config_name)\n",
    "#     print(f\"Config: {config_name} -> Transform Type: {transform_type}, Depth: {depth}, Width: {width}\")\n",
    "df[['transform', 'depth', 'width']] = df['config_name'].apply(lambda x: pd.Series(parse_config_name(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd9d4a-cafd-4ab2-b5df-e23fc1249d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(columns=['batch_latency_list', 'inference_time'])\n",
    "# batch_latency_list\tinference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21697a-476f-443c-beea-f369bccdc34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q6df = df_dropped[(df_dropped['width'] == 'widthdefault') & (df_dropped['transform'] == 'no_transform')& (df_dropped['epoch'] == 2)]\n",
    "q6df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843c6e6-f3e7-4205-9438-452ba1f34800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 주어진 데이터 중에서 epoch == 2만 필터링\n",
    "data = {\n",
    "    'flops': [2910208.0, 5007360.0, 9201664.0, 17590272.0],\n",
    "    'test_accuracy': [0.970297, 0.962896, 0.941694, 0.552455],\n",
    "    'average_inference_time': [0.000390, 0.000647, 0.001392, 0.003067],\n",
    "    'depth': ['depth2', 'depth4', 'depth8', 'depth16']  # depth 정보를 추가\n",
    "}\n",
    "\n",
    "# 1. FLOPs vs Accuracy (epoch == 2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(data['depth'])):\n",
    "    plt.scatter(data['flops'][i], data['test_accuracy'][i], label=data['depth'][i], s=100)\n",
    "\n",
    "# 그래프 설정\n",
    "plt.xlabel('FLOPs')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('FLOPs vs Test Accuracy (Epoch 2)')\n",
    "plt.legend()  # Legend 추가\n",
    "plt.grid(True)\n",
    "plt.savefig('6_plot1.jpg')  # Loss 그래프를 JPG로 저장\n",
    "plt.close()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 2. FLOPs vs Latency (epoch == 2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(data['depth'])):\n",
    "    plt.scatter(data['flops'][i], data['average_inference_time'][i], label=data['depth'][i], s=100)\n",
    "\n",
    "# 그래프 설정\n",
    "plt.xlabel('FLOPs')\n",
    "plt.ylabel('Average Inference Time (Latency)')\n",
    "plt.title('FLOPs vs Latency (Epoch 2)')\n",
    "plt.legend()  # Legend 추가\n",
    "plt.grid(True)\n",
    "plt.savefig('6_plot2.jpg')  # Loss 그래프를 JPG로 저장\n",
    "plt.close()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 3. Latency vs Accuracy (epoch == 2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(data['depth'])):\n",
    "    plt.scatter(data['average_inference_time'][i], data['test_accuracy'][i], label=data['depth'][i], s=100)\n",
    "\n",
    "# 그래프 설정\n",
    "plt.xlabel('Average Inference Time (Latency)')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Latency vs Test Accuracy (Epoch 2)')\n",
    "plt.legend()  # Legend 추가\n",
    "plt.grid(True)\n",
    "plt.savefig('6_plot3.jpg')  # Loss 그래프를 JPG로 저장\n",
    "plt.close()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5340b-38bc-4950-97c8-d9a54e8efa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 주어진 데이터 중에서 epoch == 2만 필터링\n",
    "data = {\n",
    "    'flops': [2910208.0, 5007360.0, 9201664.0, 17590272.0],\n",
    "    'test_accuracy': [0.970297, 0.962896, 0.941694, 0.552455],\n",
    "    'average_inference_time': [0.000390, 0.000647, 0.001392, 0.003067],\n",
    "    'depth': ['depth2', 'depth4', 'depth8', 'depth16']  # depth 정보를 추가\n",
    "}\n",
    "\n",
    "# Subplot을 1x3 형식으로 설정\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. FLOPs vs Accuracy (subplot 1)\n",
    "for i in range(len(data['depth'])):\n",
    "    axes[0].scatter(data['flops'][i], data['test_accuracy'][i], label=data['depth'][i], s=100)\n",
    "axes[0].set_xlabel('FLOPs')\n",
    "axes[0].set_ylabel('Test Accuracy')\n",
    "axes[0].set_title('FLOPs vs Test Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 2. FLOPs vs Latency (subplot 2)\n",
    "for i in range(len(data['depth'])):\n",
    "    axes[1].scatter(data['flops'][i], data['average_inference_time'][i], label=data['depth'][i], s=100)\n",
    "axes[1].set_xlabel('FLOPs')\n",
    "axes[1].set_ylabel('Average Inference Time (Latency)')\n",
    "axes[1].set_title('FLOPs vs Latency')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# 3. Latency vs Accuracy (subplot 3)\n",
    "for i in range(len(data['depth'])):\n",
    "    axes[2].scatter(data['average_inference_time'][i], data['test_accuracy'][i], label=data['depth'][i], s=100)\n",
    "axes[2].set_xlabel('Average Inference Time (Latency)')\n",
    "axes[2].set_ylabel('Test Accuracy')\n",
    "axes[2].set_title('Latency vs Test Accuracy')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig('6_plot_sub.jpg')  # Loss 그래프를 JPG로 저장\n",
    "plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396caa11-bcf7-4469-8d6b-7c6095232666",
   "metadata": {},
   "source": [
    "## Question 7 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74387157-9d09-42bb-becc-5b8019853618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('check/width_results.csv')\n",
    "\n",
    "# Sample dataset row with config_name\n",
    "config_name_data = list(df['config_name'])\n",
    "\n",
    "# Function to split config_name into transform_type, depth, and width\n",
    "def parse_config_name(cofig_name):\n",
    "    parts = config_name.split('_')\n",
    "    transform_type = '_'.join(parts[:-2])  # Extract the transform type\n",
    "    depth = parts[-2]  # Extract the depth\n",
    "    width = parts[-1]  # Extract the width\n",
    "    return transform_type, depth, width\n",
    "\n",
    "# # Apply the function to config_name_data\n",
    "# for config_name in config_name_data:\n",
    "#     transform_type, depth, width = parse_config_name(config_name)\n",
    "#     print(f\"Config: {config_name} -> Transform Type: {transform_type}, Depth: {depth}, Width: {width}\")\n",
    "df[['transform', 'depth', 'width']] = df['config_name'].apply(lambda x: pd.Series(parse_config_name(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6133da-4327-4285-b4e5-fbaa022a1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(columns=['batch_latency_list', 'inference_time'])\n",
    "# batch_latency_list\tinference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2418e2-b591-43a9-8ea9-74c2f4398eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q7df = df_dropped[(df_dropped['epoch'] == 2)]\n",
    "q7df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd174a-45ef-4269-a37e-11556669936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 설정\n",
    "data = {\n",
    "    'flops': [951552.0, 1133056.0, 1594368.0, 7114752.0, 21815296.0],\n",
    "    'test_accuracy': [0.970897, 0.965997, 0.964896, 0.939194, 0.943794],\n",
    "    'average_inference_time': [0.000219, 0.000244, 0.000330, 0.000861, 0.003251],\n",
    "    'depth': ['width128', 'width256', 'width512', 'width2048', 'width4096']  # width 정보 추가\n",
    "}\n",
    "\n",
    "# Subplot을 1x3 형식으로 설정\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. FLOPs vs Accuracy (subplot 1)\n",
    "for i in range(len(data['depth'])):\n",
    "    axes[0].scatter(data['flops'][i], data['test_accuracy'][i], label=data['depth'][i], s=100)\n",
    "axes[0].set_xlabel('FLOPs')\n",
    "axes[0].set_ylabel('Test Accuracy')\n",
    "axes[0].set_title('FLOPs vs Test Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 2. FLOPs vs Latency (subplot 2)\n",
    "for i in range(len(data['depth'])):\n",
    "    axes[1].scatter(data['flops'][i], data['average_inference_time'][i], label=data['depth'][i], s=100)\n",
    "axes[1].set_xlabel('FLOPs')\n",
    "axes[1].set_ylabel('Average Inference Time (Latency)')\n",
    "axes[1].set_title('FLOPs vs Latency')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# 3. Latency vs Accuracy (subplot 3)\n",
    "for i in range(len(data['depth'])):\n",
    "    axes[2].scatter(data['average_inference_time'][i], data['test_accuracy'][i], label=data['depth'][i], s=100)\n",
    "axes[2].set_xlabel('Average Inference Time (Latency)')\n",
    "axes[2].set_ylabel('Test Accuracy')\n",
    "axes[2].set_title('Latency vs Test Accuracy')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.tight_layout()\n",
    "plt.savefig('7_plot_sub.jpg')  # Loss 그래프를 JPG로 저장\n",
    "plt.close()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1c844-a772-421f-a439-fd73a07641a0",
   "metadata": {},
   "source": [
    "## Question 8 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3c860-b3d4-41d5-a417-f68c83d30115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('check/augmentation_results.csv')\n",
    "\n",
    "# Sample dataset row with config_name\n",
    "config_name_data = list(df['config_name'])\n",
    "\n",
    "# Function to split config_name into transform_type, depth, and width\n",
    "def parse_config_name(cofig_name):\n",
    "    parts = config_name.split('_')\n",
    "    transform_type = '_'.join(parts[:-2])  # Extract the transform type\n",
    "    depth = parts[-2]  # Extract the depth\n",
    "    width = parts[-1]  # Extract the width\n",
    "    return transform_type, depth, width\n",
    "\n",
    "# # Apply the function to config_name_data\n",
    "# for config_name in config_name_data:\n",
    "#     transform_type, depth, width = parse_config_name(config_name)\n",
    "#     print(f\"Config: {config_name} -> Transform Type: {transform_type}, Depth: {depth}, Width: {width}\")\n",
    "df[['transform', 'depth', 'width']] = df['config_name'].apply(lambda x: pd.Series(parse_config_name(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f4fee-27cb-4a36-a6dc-f127d47cb317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(columns=['batch_latency_list', 'inference_time'])\n",
    "# batch_latency_list\tinference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b6662-4384-4731-aeea-c0d4c115777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q8df = df_dropped[(df_dropped['epoch'] == 2)]\n",
    "q8df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40a64d-2992-4f83-9910-cd88557bdc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 설정\n",
    "data = {\n",
    "    'flops': [2910208.0, 2516992.0, 2308096.0, 2157568.0, 2516992.0, 2308096.0, 2157568.0],\n",
    "    'test_accuracy': [0.970297, 0.958796, 0.959096, 0.796780, 0.960896, 0.973697, 0.957396],\n",
    "    'average_inference_time': [0.000400, 0.000369, 0.000431, 0.000321, 0.000364, 0.000334, 0.000314],\n",
    "    'label': ['no_transform', 'crop_20', 'crop_14', 'crop_7', 'resize_20', 'resize_14', 'resize_7']  # depth 정보 추가\n",
    "}\n",
    "\n",
    "# 마커 스타일 설정 (모양 구분)\n",
    "markers = {\n",
    "    'no_transform': 'o',  # 원\n",
    "    'resize_7': 's',      # 네모\n",
    "    'resize_14': '^',     # 세모\n",
    "    'resize_20': '*',     # 별\n",
    "    'crop_7': 's',        # 네모\n",
    "    'crop_14': '^',       # 세모\n",
    "    'crop_20': '*'        # 별\n",
    "}\n",
    "\n",
    "# 색상 설정 (레이블 구분)\n",
    "colors = {\n",
    "    'no_transform': 'blue',\n",
    "    'resize': 'green',\n",
    "    'crop': 'orange'\n",
    "}\n",
    "\n",
    "# Subplot을 1x3 형식으로 설정\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# 1. FLOPs vs Accuracy (subplot 1)\n",
    "for i in range(len(data['label'])):\n",
    "    label = data['label'][i]\n",
    "    # resize, crop, no_transform 별로 색상 선택\n",
    "    color = colors['no_transform'] if 'no_transform' in label else (colors['resize'] if 'resize' in label else colors['crop'])\n",
    "    marker = markers[label]\n",
    "    axes[0].scatter(data['flops'][i], data['test_accuracy'][i], label=label, color=color, marker=marker, s=100)\n",
    "axes[0].set_xlabel('FLOPs')\n",
    "axes[0].set_ylabel('Test Accuracy')\n",
    "axes[0].set_title('FLOPs vs Test Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# 2. FLOPs vs Latency (subplot 2)\n",
    "for i in range(len(data['label'])):\n",
    "    label = data['label'][i]\n",
    "    color = colors['no_transform'] if 'no_transform' in label else (colors['resize'] if 'resize' in label else colors['crop'])\n",
    "    marker = markers[label]\n",
    "    axes[1].scatter(data['flops'][i], data['average_inference_time'][i], label=label, color=color, marker=marker, s=100)\n",
    "axes[1].set_xlabel('FLOPs')\n",
    "axes[1].set_ylabel('Average Inference Time (Latency)')\n",
    "axes[1].set_title('FLOPs vs Latency')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# 3. Latency vs Accuracy (subplot 3)\n",
    "for i in range(len(data['label'])):\n",
    "    label = data['label'][i]\n",
    "    color = colors['no_transform'] if 'no_transform' in label else (colors['resize'] if 'resize' in label else colors['crop'])\n",
    "    marker = markers[label]\n",
    "    axes[2].scatter(data['average_inference_time'][i], data['test_accuracy'][i], label=label, color=color, marker=marker, s=100)\n",
    "axes[2].set_xlabel('Average Inference Time (Latency)')\n",
    "axes[2].set_ylabel('Test Accuracy')\n",
    "axes[2].set_title('Latency vs Test Accuracy')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "# 그래프 출력\n",
    "plt.tight_layout()\n",
    "plt.savefig('8_plot_sub.jpg')  # Loss 그래프를 JPG로 저장\n",
    "plt.close()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868fa5e-60ff-4c7f-923e-0c56d20a3c22",
   "metadata": {},
   "source": [
    "## Question 9 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab07575-7aef-49a7-9037-f1a5e26bcf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('check/results.csv')\n",
    "df1_dropped = df1.drop(columns=['batch_latency_list', 'inference_time'])\n",
    "df2 = pd.read_csv('check/depth_results.csv')\n",
    "df2_dropped = df2.drop(columns=['batch_latency_list', 'inference_time'])\n",
    "df3 = pd.read_csv('check/width_results.csv')\n",
    "df3_dropped = df3.drop(columns=['batch_latency_list', 'inference_time'])\n",
    "df4 = pd.read_csv('check/augmentation_results.csv')\n",
    "df4_dropped = df4.drop(columns=['batch_latency_list', 'inference_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e7b88-f634-4247-a987-3ff0fb6c73db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('check/7by7and128_results.csv')\n",
    "df5_dropped = df5.drop(columns=['batch_latency_list', 'inference_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b81e30f-e4f9-4f68-bf2e-e07fc6ef5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.concat([df1_dropped, df2_dropped, df3_dropped, df4_dropped, df5_dropped])\n",
    "DF_unique = DF.drop_duplicates(subset=['config_name'], keep='last')\n",
    "df_sorted = DF_unique.sort_values(by='config_name', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26772a-814f-4f2a-8ea1-7b1fa0320e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data (your DataFrame)\n",
    "data = {\n",
    "    'config_name': [\n",
    "        'crop_14_depth2_width1024', 'crop_20_depth2_width1024', 'crop_20_depth2_width2048', 'crop_20_depth2_widthdefault',\n",
    "        'crop_20_depth3_widthdefault', 'crop_7_depth2_width1024', 'no_transform_depth16_widthdefault', 'no_transform_depth2_width1024',\n",
    "        'no_transform_depth2_width128', 'resize_14_depth2_width1024', 'resize_20_depth2_width1024'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Custom function to split the config_name into data, depth, and width\n",
    "def split_config_name(config_name):\n",
    "    parts = config_name.split('_')\n",
    "    \n",
    "    if parts[0] == 'no':  # Handle no_transform case separately\n",
    "        data = 'no_transform'\n",
    "        depth = parts[2]  # depth value is in the second part\n",
    "        width = '_'.join(parts[3:])  # width is the remaining part\n",
    "    else:\n",
    "        data = f\"{parts[0]}_{parts[1]}\"  # crop_14, resize_20, etc.\n",
    "        depth = parts[2]  # depth value (depth2, depth3, etc.)\n",
    "        width = '_'.join(parts[3:])  # width is the remaining part\n",
    "    \n",
    "    return pd.Series([data, depth, width])\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df_sorted[['data', 'depth', 'width']] = df_sorted['config_name'].apply(split_config_name)\n",
    "# Step 1: Replace 'widthdefault' with 'width1024' in the 'width' column\n",
    "df_sorted['width'] = df_sorted['width'].replace('widthdefault', 'width1024')\n",
    "\n",
    "# Step 2: Remove rows where 'depth' is 'depth3'\n",
    "df_sorted = df_sorted[df_sorted['depth'] != 'depth3']\n",
    "\n",
    "df_sorted['depth'] = df_sorted['depth'].str.extract('(\\d+)')\n",
    "\n",
    "# Step 2: Extract only the numeric part from the 'width' column (e.g., 'width1024' becomes '1024')\n",
    "df_sorted['width'] = df_sorted['width'].str.extract('(\\d+)')\n",
    "\n",
    "# Convert the 'depth' and 'width' columns to integers for consistency\n",
    "df_sorted['depth'] = df_sorted['depth'].astype(int)\n",
    "df_sorted['width'] = df_sorted['width'].astype(int)\n",
    "\n",
    "df_sorted = df_sorted[df_sorted['config_name'] != 'no_transform_depth2_widthdefault']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047d704-4a70-464c-934c-2f10b61feab9",
   "metadata": {},
   "source": [
    "## Question 10 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f71c4d-8238-43fb-b3c1-4c3b64bafd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flops = [\n",
    "    2308096.0, 2516992.0, 6721536.0, 2157568.0, 198912.0,\n",
    "    2910208.0, 951552.0, 7114752.0, 1133056.0, 21815296.0,\n",
    "    1594368.0, 5007360.0, 9201664.0, 2308096.0, 6512640.0,\n",
    "    2516992.0, 6721536.0, 2157568.0, 198912.0\n",
    "]\n",
    "\n",
    "test_accuracy = [\n",
    "    0.959096, 0.958796, 0.966697, 0.796780, 0.795480,\n",
    "    0.970297, 0.970897, 0.939194, 0.965997, 0.943794,\n",
    "    0.964896, 0.962896, 0.941694, 0.973697, 0.956796,\n",
    "    0.960896, 0.966697, 0.957396, 0.952295\n",
    "]\n",
    "\n",
    "average_inference_time = [\n",
    "    0.000431, 0.000369, 0.000817, 0.000321, 0.000144,\n",
    "    0.000400, 0.000219, 0.000861, 0.000244, 0.003251,\n",
    "    0.000330, 0.000647, 0.001392, 0.000334, 0.000681,\n",
    "    0.000364, 0.000784, 0.000314, 0.000156\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    'crop_14_depth2_width1024', 'crop_20_depth2_width1024', 'crop_20_depth2_width2048', \n",
    "    'crop_7_depth2_width1024', 'crop_7_depth2_width128', 'no_transform_depth2_width1024', \n",
    "    'no_transform_depth2_width128', 'no_transform_depth2_width2048', 'no_transform_depth2_width256', \n",
    "    'no_transform_depth2_width4096', 'no_transform_depth2_width512', 'no_transform_depth4_width1024', \n",
    "    'no_transform_depth8_width1024', 'resize_14_depth2_width1024', 'resize_14_depth2_width2048', \n",
    "    'resize_20_depth2_width1024', 'resize_20_depth2_width2048', 'resize_7_depth2_width1024', 'resize_7_depth2_width128'\n",
    "]\n",
    "\n",
    "\n",
    "# Markers based on different width\n",
    "markers = {\n",
    "    '128': '*',    # Star for width 128\n",
    "    '256': '^',    # Triangle up for width 256\n",
    "    '512': 's',    # Square for width 512\n",
    "    '1024': 'o',   # Circle for width 1024\n",
    "    '2048': 'D',   # Diamond for width 2048\n",
    "    '4096': 'P',   # Plus for width 4096\n",
    "}\n",
    "\n",
    "# Extract width from labels and assign markers\n",
    "def extract_width(label):\n",
    "    return label.split('_')[-1].replace('width', '')\n",
    "\n",
    "assigned_markers = [markers.get(extract_width(label), 'o') for label in labels]\n",
    "\n",
    "# Colors based on data type\n",
    "colors = [\n",
    "    'magenta', 'magenta', 'magenta', 'magenta', 'magenta', \n",
    "    'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', \n",
    "    'green', 'green', 'green', 'green', 'green', 'green'\n",
    "]\n",
    "\n",
    "# Filled markers for depth 4 and 8\n",
    "filled = ['no_transform_depth4_width1024', 'no_transform_depth8_width1024']\n",
    "\n",
    "# Line width based on resolution size\n",
    "line_width = [\n",
    "    0.6 if '7' in label else 1.2 if '14' in label else 3.0 for label in labels\n",
    "]\n",
    "\n",
    "# Create the subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot 1: FLOPs vs Test Accuracy\n",
    "for i in range(len(flops)):\n",
    "    markerfacecolor = colors[i] if labels[i] in filled else 'none'\n",
    "    axs[0].scatter(flops[i], test_accuracy[i], edgecolor=colors[i], facecolor=markerfacecolor, \n",
    "                   marker=assigned_markers[i], s=100, linewidths=line_width[i], label=labels[i])\n",
    "axs[0].set_xlabel('FLOPs')\n",
    "axs[0].set_ylabel('Test Accuracy')\n",
    "axs[0].set_title('FLOPs vs Test Accuracy')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot 2: FLOPs vs Latency\n",
    "for i in range(len(flops)):\n",
    "    markerfacecolor = colors[i] if labels[i] in filled else 'none'\n",
    "    axs[1].scatter(flops[i], average_inference_time[i], edgecolor=colors[i], facecolor=markerfacecolor, \n",
    "                   marker=assigned_markers[i], s=100, linewidths=line_width[i], label=labels[i])\n",
    "axs[1].set_xlabel('FLOPs')\n",
    "axs[1].set_ylabel('Latency')\n",
    "axs[1].set_title('FLOPs vs Latency')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot 3: Latency vs Test Accuracy\n",
    "for i in range(len(flops)):\n",
    "    markerfacecolor = colors[i] if labels[i] in filled else 'none'\n",
    "    axs[2].scatter(average_inference_time[i], test_accuracy[i], edgecolor=colors[i], facecolor=markerfacecolor, \n",
    "                   marker=assigned_markers[i], s=100, linewidths=line_width[i], label=labels[i])\n",
    "axs[2].set_xlabel('Latency')\n",
    "axs[2].set_ylabel('Test Accuracy')\n",
    "axs[2].set_title('Latency vs Test Accuracy')\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Create a single legend for all subplots\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', ncol=5, bbox_to_anchor=(0.5, 1.05), fontsize='small')\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.savefig('9_plot_sub.jpg', dpi=300, bbox_inches='tight')  # Save the plot as a JPG file with proper settings\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6179a61-a7bd-4958-915d-0c381fbc0559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
